{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "811a1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree\n",
    "import codecs\n",
    "\n",
    "fileAllRecords = codecs.open (r'Path.txt',\n",
    "            \"r\",  encoding = 'utf-8')\n",
    "\n",
    "allStrings = fileAllRecords.readlines()\n",
    "new_file = codecs.open(r'Path', 'w',   encoding = 'utf-8')\n",
    "\n",
    "for string in allStrings:\n",
    "    if len(string) > 20:\n",
    "        new_file.write(string)\n",
    "\n",
    "full_new_corpus = open(r'Path.txt', 'r',  encoding = 'utf-8')\n",
    "lines = full_new_corpus.readlines()\n",
    "\n",
    "sentences = []\n",
    "for sent_str in lines:\n",
    "    tokens = re.sub(\"[a-z0-9]+.,´-\", \" \", sent_str.lower()).split()\n",
    "    sentences.append(tokens)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=sentences, vector_size=50, window=4, min_count=3, workers=4, sg=0)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=100)\n",
    "model.save('model_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "320ba1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Asthma with status asthmaticus (disorder)\n",
      "1     Varicose veins of lower extremity (disorder)\n",
      "2                             Gastritis (disorder)\n",
      "3                           Hemorrhoids (disorder)\n",
      "4                               Headache (finding)\n",
      "5                        Lightheadedness (finding)\n",
      "6         Benign essential hypertension (disorder)\n",
      "7                                Fatigue (finding)\n",
      "8                     Disorder of liver (disorder)\n",
      "9                         Hiatal hernia (disorder)\n",
      "10                        Cholecystitis (disorder)\n",
      "11                       Pyelonephritis (disorder)\n",
      "12             Diabetes mellitus type 2 (disorder)\n",
      "13       Chronic ischemic heart disease (disorder)\n",
      "14         Body mass index 30+ - obesity (finding)\n",
      "15        Calculus of kidney and ureter (disorder)\n",
      "16          Scoliosis of thoracic spine (disorder)\n",
      "17                 Chronic pancreatitis (disorder)\n",
      "18               Duodenal ulcer disease (disorder)\n",
      "19                       Chronic anemia (disorder)\n",
      "20              Edema of lower extremity (finding)\n",
      "21               Chronic kidney disease (disorder)\n",
      "Name:  Atherosclerosis of coronary artery (disorder), dtype: object\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, Conv2D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.layers import Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import pandas\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#get data in words\n",
    "some_data = pandas.read_csv(r\"test.csv\",\n",
    "                            sep=' ; ', encoding = 'utf-8', engine='python', index_col=False)\n",
    "\n",
    "labels = some_data.iloc[:,0]\n",
    "samples = some_data.iloc[:,1]\n",
    "\n",
    "print(samples);\n",
    "\n",
    "num_of_diagnoses = len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "401b251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "samples ['asthma with status asthmaticus disorder ', 'varicose veins of lower extremity disorder ', 'gastritis disorder ', 'hemorrhoids disorder ', 'headache finding ', 'lightheadedness finding ', 'benign essential hypertension disorder ', 'fatigue finding ', 'disorder of liver disorder ', 'hiatal hernia disorder ', 'cholecystitis disorder ', 'pyelonephritis disorder ', 'diabetes mellitus type disorder ', 'chronic ischemic heart disease disorder ', 'body mass index obesity finding ', 'calculus of kidney and ureter disorder ', 'scoliosis of thoracic spine disorder ', 'chronic pancreatitis disorder ', 'duodenal ulcer disease disorder ', 'chronic anemia disorder ', 'edema of lower extremity finding ', 'chronic kidney disease disorder ']\n",
      "vocab len 458\n",
      "inx 0\n",
      "the\n",
      "inx 1\n",
      "of\n",
      "inx 2\n",
      "in\n",
      "inx 3\n",
      "is\n",
      "inx 4\n",
      "a\n",
      "inx 5\n",
      "/\n",
      "inx 6\n",
      "not\n",
      "inx 7\n",
      "-\n",
      "inx 8\n",
      "and\n",
      "inx 9\n",
      "l\n",
      "inx 10\n",
      "are\n",
      "inx 11\n",
      "with\n",
      "inx 12\n",
      "no\n",
      "inx 13\n",
      "1\n",
      "inx 14\n",
      "%\n",
      "inx 15\n",
      "times\n",
      "inx 16\n",
      "2\n",
      "inx 17\n",
      "on\n",
      "inx 18\n",
      "mmol/l\n",
      "inx 19\n",
      "to\n",
      "inx 20\n",
      "blood\n",
      "inx 21\n",
      "was\n",
      "inx 22\n",
      "left\n",
      "inx 23\n",
      "from\n",
      "inx 24\n",
      "right\n",
      "inx 25\n",
      "3\n",
      "inx 26\n",
      "mm,\n",
      "inx 27\n",
      "u\n",
      "inx 28\n",
      "o\n",
      "inx 29\n",
      "dated\n",
      "inx 30\n",
      "mmol\n",
      "inx 31\n",
      "p.z.\n",
      "inx 32\n",
      "organs\n",
      "inx 33\n",
      "clinic\n",
      "inx 34\n",
      "clinical\n",
      "inx 35\n",
      "at\n",
      "inx 36\n",
      "g/l\n",
      "inx 37\n",
      "total\n",
      "inx 38\n",
      "g\n",
      "inx 39\n",
      "no.\n",
      "inx 40\n",
      "tab\n",
      "inx 41\n",
      "(1\n",
      "inx 42\n",
      "4\n",
      "inx 43\n",
      "day\n",
      "inx 44\n",
      "without\n",
      "inx 45\n",
      "chest\n",
      "inx 46\n",
      "m\n",
      "inx 47\n",
      "heart\n",
      "inx 48\n",
      "general\n",
      "inx 49\n",
      "hospital\n",
      "inx 50\n",
      "enlarged,\n",
      "inx 51\n",
      "by\n",
      "inx 52\n",
      "*109/l\n",
      "inx 53\n",
      "there\n",
      "inx 54\n",
      "complaints\n",
      "inx 55\n",
      "stage\n",
      "inx 56\n",
      "test:\n",
      "inx 57\n",
      "km\n",
      "inx 58\n",
      "biochemical\n",
      "inx 59\n",
      "name\n",
      "inx 60\n",
      "after\n",
      "inx 61\n",
      "normal\n",
      "inx 62\n",
      "even,\n",
      "inx 63\n",
      "protein\n",
      "inx 64\n",
      "contours\n",
      "inx 65\n",
      "satisfactory\n",
      "inx 66\n",
      "test\n",
      "inx 67\n",
      "year;\n",
      "inx 68\n",
      "b.\n",
      "inx 69\n",
      "x-ray\n",
      "inx 70\n",
      "therapy\n",
      "inx 71\n",
      "condition\n",
      "inx 72\n",
      "morning\n",
      "inx 73\n",
      "military\n",
      "inx 74\n",
      "both\n",
      "inx 75\n",
      "treatment\n",
      "inx 76\n",
      "results\n",
      "inx 77\n",
      "fracture\n",
      "inx 78\n",
      "e\n",
      "inx 79\n",
      "away\n",
      "inx 80\n",
      "run\n",
      "inx 81\n",
      "unit.\n",
      "inx 82\n",
      "pathological\n",
      "inx 83\n",
      "bilirubin\n",
      "inx 84\n",
      "rev.\n",
      "inx 85\n",
      "abdominal\n",
      "inx 86\n",
      "ecg\n",
      "inx 87\n",
      "a.\n",
      "inx 88\n",
      "cm,\n",
      "inx 89\n",
      "aorta\n",
      "inx 90\n",
      "mucosa\n",
      "inx 91\n",
      "u/l\n",
      "inx 92\n",
      "ventricle.\n",
      "inx 93\n",
      "chronic\n",
      "inx 94\n",
      "background\n",
      "inx 95\n",
      "ig\n",
      "inx 96\n",
      "tab.\n",
      "inx 97\n",
      "creatinine\n",
      "inx 98\n",
      "10\n",
      "inx 99\n",
      "dysfunction\n",
      "inx 100\n",
      "recommended:\n",
      "inx 101\n",
      "dilated.\n",
      "inx 102\n",
      "old),\n",
      "inx 103\n",
      "mol/l\n",
      "inx 104\n",
      "anterior\n",
      "inx 105\n",
      "years\n",
      "inx 106\n",
      "cavity\n",
      "inx 107\n",
      "conclusion:\n",
      "inx 108\n",
      "liver\n",
      "inx 109\n",
      "regimen,\n",
      "inx 110\n",
      "diet,\n",
      "inx 111\n",
      "vessels\n",
      "inx 112\n",
      "then\n",
      "inx 113\n",
      "pain\n",
      "inx 114\n",
      "structure\n",
      "inx 115\n",
      "aortic\n",
      "inx 116\n",
      "transparent\n",
      "inx 117\n",
      "coronary\n",
      "inx 118\n",
      "glucose\n",
      "inx 119\n",
      "cm\n",
      "inx 120\n",
      "he\n",
      "inx 121\n",
      "c.\n",
      "inx 122\n",
      "admitted\n",
      "inx 123\n",
      "norm\n",
      "inx 124\n",
      "ed\n",
      "inx 125\n",
      "discharged\n",
      "inx 126\n",
      "lower\n",
      "inx 127\n",
      "laboratory\n",
      "inx 128\n",
      "therapy,\n",
      "inx 129\n",
      "weeks\n",
      "inx 130\n",
      "region\n",
      "inx 131\n",
      "patient's\n",
      "inx 132\n",
      "does\n",
      "inx 133\n",
      "k\n",
      "inx 134\n",
      "form\n",
      "inx 135\n",
      "acid\n",
      "inx 136\n",
      "changes.\n",
      "inx 137\n",
      "4-6\n",
      "inx 138\n",
      "frequency\n",
      "inx 139\n",
      "diagnosis:\n",
      "inx 140\n",
      "under\n",
      "inx 141\n",
      "an\n",
      "inx 142\n",
      "syndrome\n",
      "inx 143\n",
      "duodenal\n",
      "inx 144\n",
      "condition.\n",
      "inx 145\n",
      "unit\n",
      "inx 146\n",
      "observation\n",
      "inx 147\n",
      "2.\n",
      "inx 148\n",
      "leave.\n",
      "inx 149\n",
      "0-2\n",
      "inx 150\n",
      "meals\n",
      "inx 151\n",
      "require\n",
      "inx 152\n",
      "sick\n",
      "inx 153\n",
      "about\n",
      "inx 154\n",
      "30\n",
      "inx 155\n",
      "per\n",
      "inx 156\n",
      "d\n",
      "inx 157\n",
      "born\n",
      "inx 158\n",
      "8.4-53.5\n",
      "inx 159\n",
      "ast\n",
      "inx 160\n",
      "7-39.7\n",
      "inx 161\n",
      "fibrinogen\n",
      "inx 162\n",
      "36-92\n",
      "inx 163\n",
      "cl\n",
      "inx 164\n",
      "95-108\n",
      "inx 165\n",
      "ggtp\n",
      "inx 166\n",
      "na\n",
      "inx 167\n",
      "130-150\n",
      "inx 168\n",
      "4.2-6.4\n",
      "inx 169\n",
      "6.8-26\n",
      "inx 170\n",
      "mmol/l.\n",
      "inx 171\n",
      "instrumental\n",
      "inx 172\n",
      "studies:\n",
      "inx 173\n",
      "=\n",
      "inx 174\n",
      "shoulder\n",
      "inx 175\n",
      "examination\n",
      "inx 176\n",
      "mixed\n",
      "inx 177\n",
      "r\n",
      "inx 178\n",
      "day,\n",
      "inx 179\n",
      "omeprazole\n",
      "inx 180\n",
      "0.02\n",
      "inx 181\n",
      "6\n",
      "inx 182\n",
      "3.7-7\n",
      "inx 183\n",
      "almagel\n",
      "inx 184\n",
      "spoon\n",
      "inx 185\n",
      "first\n",
      "inx 186\n",
      "disease\n",
      "inx 187\n",
      "normal.\n",
      "inx 188\n",
      "december\n",
      "inx 189\n",
      "for\n",
      "inx 190\n",
      "sinus\n",
      "inx 191\n",
      "improved.\n",
      "inx 192\n",
      "results:\n",
      "inx 193\n",
      "homogeneous,\n",
      "inx 194\n",
      "upper\n",
      "inx 195\n",
      "thrombus\n",
      "inx 196\n",
      "cavities\n",
      "inx 197\n",
      "63-87\n",
      "inx 198\n",
      "protein,\n",
      "inx 199\n",
      "dilated,\n",
      "inx 200\n",
      "mm/h\n",
      "inx 201\n",
      "esr,\n",
      "inx 202\n",
      "hb\n",
      "inx 203\n",
      "date,\n",
      "inx 204\n",
      "ultrasound\n",
      "inx 205\n",
      "lungs\n",
      "inx 206\n",
      "units.\n",
      "inx 207\n",
      "pericardium\n",
      "inx 208\n",
      "date\n",
      "inx 209\n",
      "24\n",
      "inx 210\n",
      "echogenicity\n",
      "inx 211\n",
      "analysis\n",
      "inx 212\n",
      "spleen\n",
      "inx 213\n",
      "n\n",
      "inx 214\n",
      "contours,\n",
      "inx 215\n",
      "found.\n",
      "inx 216\n",
      "lobe\n",
      "inx 217\n",
      "medical\n",
      "inx 218\n",
      "veins\n",
      "inx 219\n",
      "er.,\n",
      "inx 220\n",
      "intrahepatic\n",
      "inx 221\n",
      "mm\n",
      "inx 222\n",
      "rate\n",
      "inx 223\n",
      "projection\n",
      "inx 224\n",
      "bulb\n",
      "inx 225\n",
      "50\n",
      "inx 226\n",
      "gallbladder\n",
      "inx 227\n",
      "negative\n",
      "inx 228\n",
      "slightly\n",
      "inx 229\n",
      "location\n",
      "inx 230\n",
      "ml,\n",
      "inx 231\n",
      "joint\n",
      "inx 232\n",
      "adrenal\n",
      "inx 233\n",
      "were\n",
      "inx 234\n",
      "eos\n",
      "inx 235\n",
      "e.\n",
      "inx 236\n",
      "b\n",
      "inx 237\n",
      "mucus\n",
      "inx 238\n",
      "changed.\n",
      "inx 239\n",
      "shortness\n",
      "inx 240\n",
      "10.05\n",
      "inx 241\n",
      "albumin\n",
      "inx 242\n",
      "·\n",
      "inx 243\n",
      "acc\n",
      "inx 244\n",
      "mol\n",
      "inx 245\n",
      "units\n",
      "inx 246\n",
      "hdl\n",
      "inx 247\n",
      "alt\n",
      "inx 248\n",
      "continue\n",
      "inx 249\n",
      "limb.\n",
      "inx 250\n",
      "bilirubin,\n",
      "inx 251\n",
      "350-650\n",
      "inx 252\n",
      "academy\n",
      "inx 253\n",
      "3-8.4\n",
      "inx 254\n",
      "ldh\n",
      "inx 255\n",
      "100-220\n",
      "inx 256\n",
      "urinalysis\n",
      "inx 257\n",
      "1.0\n",
      "inx 258\n",
      "70-120\n",
      "inx 259\n",
      "thrombo\n",
      "inx 260\n",
      "0-2.37\n",
      "inx 261\n",
      "tg\n",
      "inx 262\n",
      "neck\n",
      "inx 263\n",
      "mm.\n",
      "inx 264\n",
      "carried\n",
      "inx 265\n",
      "otr\n",
      "inx 266\n",
      "according\n",
      "inx 267\n",
      "urea\n",
      "inx 268\n",
      "out:\n",
      "inx 269\n",
      "cylinders\n",
      "inx 270\n",
      "parenchyma\n",
      "inx 271\n",
      "kidneys\n",
      "inx 272\n",
      "3-5\n",
      "inx 273\n",
      "echo-kg\n",
      "inx 274\n",
      "increased\n",
      "inx 275\n",
      "sugar,\n",
      "inx 276\n",
      "2006:\n",
      "inx 277\n",
      "atherosclerosis\n",
      "inx 278\n",
      "1-2\n",
      "inx 279\n",
      "*1012/l\n",
      "inx 280\n",
      "erythrocytes\n",
      "inx 281\n",
      "leukocytes\n",
      "inx 282\n",
      "insufficiency\n",
      "inx 283\n",
      "or\n",
      "inx 284\n",
      "pressure\n",
      "inx 285\n",
      "dyscirculatory\n",
      "inx 286\n",
      "encephalopathy\n",
      "inx 287\n",
      "salts\n",
      "inx 288\n",
      "f.cl.\n",
      "inx 289\n",
      "area\n",
      "inx 290\n",
      "homogeneous\n",
      "inx 291\n",
      "genesis\n",
      "inx 292\n",
      "epithelium\n",
      "inx 293\n",
      "acetone\n",
      "inx 294\n",
      "remission.\n",
      "inx 295\n",
      "planned\n",
      "inx 296\n",
      "valves\n",
      "inx 297\n",
      "angina\n",
      "inx 298\n",
      "3.\n",
      "inx 299\n",
      "relative\n",
      "inx 300\n",
      "lf\n",
      "inx 301\n",
      "manner\n",
      "inx 302\n",
      "21.11\n",
      "inx 303\n",
      "ducts\n",
      "inx 304\n",
      "pupils\n",
      "inx 305\n",
      "bile\n",
      "inx 306\n",
      "clear\n",
      "inx 307\n",
      "53-124\n",
      "inx 308\n",
      "myocardium\n",
      "inx 309\n",
      "transparency\n",
      "inx 310\n",
      "changed,\n",
      "inx 311\n",
      "arteries,\n",
      "inx 312\n",
      "atherosclerotic\n",
      "inx 313\n",
      "ldl\n",
      "inx 314\n",
      "diastolic\n",
      "inx 315\n",
      "mitral\n",
      "inx 316\n",
      "week,\n",
      "inx 317\n",
      "evening)\n",
      "inx 318\n",
      "density\n",
      "inx 319\n",
      "1.\n",
      "inx 320\n",
      "ph\n",
      "inx 321\n",
      "color\n",
      "inx 322\n",
      "17\n",
      "inx 323\n",
      "disease.\n",
      "inx 324\n",
      "pia\n",
      "inx 325\n",
      "0.78-2.33\n",
      "inx 326\n",
      "cardiac\n",
      "inx 327\n",
      "200-400\n",
      "inx 328\n",
      "y-lp\n",
      "inx 329\n",
      "urine:\n",
      "inx 330\n",
      "pectoris\n",
      "inx 331\n",
      "iii\n",
      "inx 332\n",
      "dilated\n",
      "inx 333\n",
      "breath\n",
      "inx 334\n",
      "diagnosis\n",
      "inx 335\n",
      "right-sided\n",
      "inx 336\n",
      "16.05\n",
      "inx 337\n",
      "1.9-4\n",
      "inx 338\n",
      "postbulbar\n",
      "inx 339\n",
      "antigen\n",
      "inx 340\n",
      "eyes.\n",
      "inx 341\n",
      "treated\n",
      "inx 342\n",
      "examined\n",
      "inx 343\n",
      "reference\n",
      "inx 344\n",
      "academy.\n",
      "inx 345\n",
      "military-medical\n",
      "inx 346\n",
      "d.\n",
      "inx 347\n",
      "constantly\n",
      "inx 348\n",
      "taking:\n",
      "inx 349\n",
      "urea)\n",
      "inx 350\n",
      "alt,\n",
      "inx 351\n",
      "ast,\n",
      "inx 352\n",
      "fractions,\n",
      "inx 353\n",
      "(fibrinogen,\n",
      "inx 354\n",
      "(with\n",
      "inx 355\n",
      "observation:\n",
      "inx 356\n",
      "dispensary\n",
      "inx 357\n",
      "monitoring\n",
      "inx 358\n",
      "outpatient\n",
      "inx 359\n",
      "asparkam,\n",
      "inx 360\n",
      "vertebral\n",
      "inx 361\n",
      "due\n",
      "inx 362\n",
      "diameter\n",
      "inx 363\n",
      "infiltrative\n",
      "inx 364\n",
      "fresh\n",
      "inx 365\n",
      "survey\n",
      "inx 366\n",
      "antigen,\n",
      "inx 367\n",
      "hepatic\n",
      "inx 368\n",
      "features.\n",
      "inx 369\n",
      "days\n",
      "inx 370\n",
      "breakfast\n",
      "inx 371\n",
      "30.03.2007.\n",
      "inx 372\n",
      "disorders\n",
      "inx 373\n",
      "osteosynthesis\n",
      "inx 374\n",
      "aorta,\n",
      "inx 375\n",
      "5\n",
      "inx 376\n",
      "7\n",
      "inx 377\n",
      "8\n",
      "inx 378\n",
      "pl\n",
      "inx 379\n",
      "reduced.\n",
      "inx 380\n",
      "reflexes\n",
      "inx 381\n",
      "cyl\n",
      "inx 382\n",
      "lateral\n",
      "inx 383\n",
      "signs\n",
      "inx 384\n",
      "regular\n",
      "inx 385\n",
      "4.5\n",
      "inx 386\n",
      "11.12\n",
      "inx 387\n",
      "13\n",
      "inx 388\n",
      "leuc.,\n",
      "inx 389\n",
      "acute\n",
      "inx 390\n",
      "moderate\n",
      "inx 391\n",
      "pathology\n",
      "inx 392\n",
      "cm.\n",
      "inx 393\n",
      "12/11/2006:\n",
      "inx 394\n",
      "formations\n",
      "inx 395\n",
      "expanded.\n",
      "inx 396\n",
      "but\n",
      "inx 397\n",
      "two\n",
      "inx 398\n",
      "50-70%\n",
      "inx 399\n",
      "along\n",
      "inx 400\n",
      "third\n",
      "inx 401\n",
      "department\n",
      "inx 402\n",
      "mg\n",
      "inx 403\n",
      "capsule\n",
      "inx 404\n",
      "night)\n",
      "inx 405\n",
      "hour\n",
      "inx 406\n",
      "maalox\n",
      "inx 407\n",
      "22\n",
      "inx 408\n",
      "day).\n",
      "inx 409\n",
      "before\n",
      "inx 410\n",
      "minutes\n",
      "inx 411\n",
      "day),\n",
      "inx 412\n",
      "ml\n",
      "inx 413\n",
      "from.\n",
      "inx 414\n",
      "rw\n",
      "inx 415\n",
      "ymol\n",
      "inx 416\n",
      "2.0-2.7\n",
      "inx 417\n",
      "ca\n",
      "inx 418\n",
      "11-63\n",
      "inx 419\n",
      "6-66\n",
      "inx 420\n",
      "cec\n",
      "inx 421\n",
      "yy\n",
      "inx 422\n",
      "1.25-2.5\n",
      "inx 423\n",
      "7.5-15.5\n",
      "inx 424\n",
      "1,1-2,5\n",
      "inx 425\n",
      "a/g\n",
      "inx 426\n",
      "trypsin\n",
      "inx 427\n",
      "functional\n",
      "inx 428\n",
      "cardiosclerosis.\n",
      "inx 429\n",
      "hypertensive\n",
      "inx 430\n",
      "vascular\n",
      "inx 431\n",
      "duodenum\n",
      "inx 432\n",
      "study\n",
      "inx 433\n",
      "i.\n",
      "inx 434\n",
      "into\n",
      "inx 435\n",
      "walls\n",
      "inx 436\n",
      "ov\n",
      "inx 437\n",
      "pancreas\n",
      "inx 438\n",
      "calculi\n",
      "inx 439\n",
      "size.\n",
      "inx 440\n",
      "vein\n",
      "inx 441\n",
      "portal\n",
      "inx 442\n",
      "clear,\n",
      "inx 443\n",
      "ventricular\n",
      "inx 444\n",
      "second\n",
      "inx 445\n",
      "kinetics\n",
      "inx 446\n",
      "intact.\n",
      "inx 447\n",
      "sealed.\n",
      "inx 448\n",
      "free,\n",
      "inx 449\n",
      "thickened.\n",
      "inx 450\n",
      "rhythm\n",
      "inx 451\n",
      "cs\n",
      "inx 452\n",
      "dizziness,\n",
      "inx 453\n",
      "when\n",
      "inx 454\n",
      "slight\n",
      "inx 455\n",
      "neurological\n",
      "inx 456\n",
      "(atherosclerotic,\n",
      "inx 457\n",
      "night\n"
     ]
    }
   ],
   "source": [
    "#convert labels to categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoded_labels = encoder.transform(labels)\n",
    "Y_encoded = np_utils.to_categorical(encoded_labels)\n",
    "\n",
    "import re \n",
    "import pymorphy2\n",
    "\n",
    "def preprocessing_samples(samples):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    new_samples = []\n",
    "    for s in samples:\n",
    "        new_s = \"\"\n",
    "        for w in s.split():\n",
    "            r = re.compile(\"[^a-zA-Z ]+\")\n",
    "            w = r.sub('', w).lower()\n",
    "            w = morph.parse(w)[0].normal_form  \n",
    "            new_s += w + \" \"\n",
    "        new_samples.append(new_s)\n",
    "    return new_samples\n",
    "\n",
    "samples = preprocessing_samples(samples) \n",
    "\n",
    "\n",
    "#Word2Vec load\n",
    "def words_in_sample(samples):\n",
    "    \"\"\"Max number of words in one sample\"\"\"\n",
    "    max_len = 0\n",
    "    for sample in samples:\n",
    "        cur_sample = sample.split()\n",
    "        max_len = len(cur_sample) if len(cur_sample) > max_len else max_len\n",
    "    return max_len\n",
    "\n",
    "max_words_in_sample = words_in_sample(samples)\n",
    "print(\"max_words_in_sample\", max_words_in_sample)\n",
    "print(\"samples\", samples)\n",
    "\n",
    "\n",
    "#load word2vec model\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# my model\n",
    "model = Word2Vec.load(\"model_1.bin\") #model_2.bin\n",
    "\n",
    "# rusvectors model\n",
    "#word2vecModel = KeyedVectors.load_word2vec_format(\"model_1.bin\", binary=True) \n",
    "word_vectors = model\n",
    "word_vectors.save('vectors.kv')\n",
    "word2vecModel = KeyedVectors.load('vectors.kv')\n",
    "\n",
    "from collections import defaultdict\n",
    "modelWord_from_word = dict()\n",
    "\n",
    "vocab_len = len(model.wv)\n",
    "print(\"vocab len\", vocab_len);\n",
    "for inx in range(vocab_len):\n",
    "    print(\"inx\", inx)\n",
    "    print(word2vecModel.wv.index_to_key[inx])\n",
    "    word = word2vecModel.wv.index_to_key[inx]\n",
    "    #word = word2vecModel.wv.index_to_key(inx).split('_')[0]\n",
    "    modelWord_from_word[inx + 1] = word;\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_embedded_samples(samples, word2vecModel, words_in_sample):\n",
    "    \"\"\"get word2vec embeddings for given samples and words absent in given word2vec model\"\"\"\n",
    "    new_x = np.zeros((len(samples), word2vecModel.vector_size*words_in_sample))\n",
    "    absent_words = []\n",
    "    i = 0 \n",
    "    for sample in samples:\n",
    "        current_sample = text_to_word_sequence(sample)\n",
    "        newcur_x = np.zeros((1, word2vecModel.vector_size*max_words_in_sample))\n",
    "        j = 0\n",
    "        for word in current_sample:\n",
    "            if word in modelWord_from_word:\n",
    "                newcur_x[:, j:j+word2vecModel.vector_size] = (word2vecModel[modelWord_from_word[word]])\n",
    "                j += word2vecModel.vector_size\n",
    "            else:\n",
    "                absent_words.append(word)\n",
    "        new_x[i] = newcur_x\n",
    "        i += 1\n",
    "    return new_x, absent_words\n",
    "\n",
    "new_x, absentWords = get_embedded_samples(samples, word2vecModel, max_words_in_sample)\n",
    "\n",
    "def create_network():\n",
    "    model_CNN = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu',\n",
    "               input_shape=(max_words_in_sample,\n",
    "                            word2vecModel.vector_size,\n",
    "                            1),\n",
    "               data_format=\"channels_last\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        #Conv2D(64, (2, 2), activation='relu'),\n",
    "        #MaxPooling2D(pool_size=(2, 2)),\n",
    "        #Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_of_diagnoses, activation='softmax')])\n",
    "\n",
    "    model_CNN.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4940898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history_CNN.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76698a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f85bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 3.0910 - accuracy: 0.0000e+00 - val_loss: 3.0959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0896 - accuracy: 0.0588 - val_loss: 3.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0886 - accuracy: 0.0588 - val_loss: 3.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0877 - accuracy: 0.0588 - val_loss: 3.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0870 - accuracy: 0.0588 - val_loss: 3.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0863 - accuracy: 0.0588 - val_loss: 3.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.0856 - accuracy: 0.0588 - val_loss: 3.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0850 - accuracy: 0.0588 - val_loss: 3.1139 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0844 - accuracy: 0.0588 - val_loss: 3.1159 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.0838 - accuracy: 0.0588 - val_loss: 3.1178 - val_accuracy: 0.0000e+00\n",
      "acc  0.0\n",
      "F1  0.0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caast\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 3.0910 - accuracy: 0.0588 - val_loss: 3.0959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0896 - accuracy: 0.0588 - val_loss: 3.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0886 - accuracy: 0.0588 - val_loss: 3.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0877 - accuracy: 0.0588 - val_loss: 3.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0870 - accuracy: 0.0588 - val_loss: 3.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0863 - accuracy: 0.0588 - val_loss: 3.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0856 - accuracy: 0.0588 - val_loss: 3.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0850 - accuracy: 0.0588 - val_loss: 3.1139 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.0844 - accuracy: 0.0588 - val_loss: 3.1159 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0838 - accuracy: 0.0588 - val_loss: 3.1178 - val_accuracy: 0.0000e+00\n",
      "acc  0.0\n",
      "F1  0.0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caast\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 3.0910 - accuracy: 0.0556 - val_loss: 3.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0899 - accuracy: 0.0556 - val_loss: 3.1000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0891 - accuracy: 0.0556 - val_loss: 3.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0884 - accuracy: 0.0556 - val_loss: 3.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0878 - accuracy: 0.0556 - val_loss: 3.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0872 - accuracy: 0.0556 - val_loss: 3.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.0867 - accuracy: 0.0556 - val_loss: 3.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0862 - accuracy: 0.0556 - val_loss: 3.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0857 - accuracy: 0.0556 - val_loss: 3.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0853 - accuracy: 0.0556 - val_loss: 3.1194 - val_accuracy: 0.0000e+00\n",
      "acc  0.0\n",
      "F1  0.0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caast\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 3.0910 - accuracy: 0.0556 - val_loss: 3.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0899 - accuracy: 0.0556 - val_loss: 3.1000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0891 - accuracy: 0.0556 - val_loss: 3.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0884 - accuracy: 0.0556 - val_loss: 3.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0878 - accuracy: 0.0556 - val_loss: 3.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0872 - accuracy: 0.0556 - val_loss: 3.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0867 - accuracy: 0.0556 - val_loss: 3.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0862 - accuracy: 0.0556 - val_loss: 3.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0857 - accuracy: 0.0556 - val_loss: 3.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0853 - accuracy: 0.0556 - val_loss: 3.1194 - val_accuracy: 0.0000e+00\n",
      "acc  0.0\n",
      "F1  0.0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caast\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 965ms/step - loss: 3.0910 - accuracy: 0.0556 - val_loss: 3.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0899 - accuracy: 0.0556 - val_loss: 3.1000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.0891 - accuracy: 0.0556 - val_loss: 3.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0884 - accuracy: 0.0556 - val_loss: 3.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0878 - accuracy: 0.0556 - val_loss: 3.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0872 - accuracy: 0.0556 - val_loss: 3.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.0867 - accuracy: 0.0556 - val_loss: 3.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0862 - accuracy: 0.0556 - val_loss: 3.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0857 - accuracy: 0.0556 - val_loss: 3.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0853 - accuracy: 0.0556 - val_loss: 3.1194 - val_accuracy: 0.0000e+00\n",
      "acc  0.0\n",
      "F1  0.0\n",
      "0.0\n",
      "Accuracy: 0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_splits = 5\n",
    "n_epochs = 10\n",
    "\n",
    "x_CNN = new_x.reshape(new_x.shape[0], max_words_in_sample, word2vecModel.vector_size, 1)\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=2)\n",
    "kf.get_n_splits(x_CNN)\n",
    "\n",
    "f1_score_all = []\n",
    "for train_index, test_index in kf.split(x_CNN):\n",
    "    X_train, X_test = x_CNN[train_index], x_CNN[test_index]\n",
    "    y_train, y_test = Y_encoded[train_index], Y_encoded[test_index]\n",
    "\n",
    "    model_CNN = create_network()\n",
    "\n",
    "    history_CNN = model_CNN.fit(X_train, y_train,\n",
    "                                epochs=n_epochs,\n",
    "                                verbose=1,\n",
    "                                batch_size = 128,\n",
    "                                validation_data=(X_test, y_test))\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history_CNN.history['accuracy'])\n",
    "    plt.plot(history_CNN.history['val_accuracy'])\n",
    "    plt.title('CNN accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "    # evaluate\n",
    "    #accuracy_score(y, np.argmax(pred_train, axis=1))\n",
    "    acc = model_CNN.evaluate(X_test, y_test, verbose = 0)[1]\n",
    "    print(\"acc \", model_CNN.evaluate(X_test, y_test, verbose = 0)[1])\n",
    "    pred_cnn = np.argmax(model_CNN.predict(X_test),axis=1)\n",
    "    metrica = f1_score(np.argmax(y_test,axis =1), pred_cnn, average='micro')\n",
    "    print(\"F1 \", metrica)\n",
    "    f1_score_all.append(metrica)\n",
    "    \n",
    "    #_, accuracy += model_CNN.evaluate(X_train, y_train)\n",
    "\n",
    "    \n",
    "print(sum(f1_score_all)/len(f1_score_all))\n",
    "print('Accuracy: %.2f' % (acc*100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e791d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
